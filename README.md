# LLM-fullstack
A Fullstack application using ollama, flask, postgre and next.js. The purpose is to have a chatbot that uses RAG with my personal obsidian knowledgebase. 

### TODOs
- [x] Create MVP with prompts and responses
- [x] Have a working chat with chat history
- [x] Create Vector database with pgvector and create module for Retrieval Augmented Generation (RAG)
- [x] Style Interface a little bit
- [ ] Create component to embed obsidian knowlegdebase
- [ ] Add Options to each chat for e.g. adding context
- [ ] Add Option to delete messages and chats
- [ ] Dockerize application for fast deployment

